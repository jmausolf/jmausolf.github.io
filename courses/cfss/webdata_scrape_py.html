<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Joshua G. Mausolf" />


<title>Web Scraping with Python</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/readable.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-45631879-2', 'auto');
  ga('send', 'pageview');

</script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 66px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 71px;
  margin-top: -71px;
}

.section h2 {
  padding-top: 71px;
  margin-top: -71px;
}
.section h3 {
  padding-top: 71px;
  margin-top: -71px;
}
.section h4 {
  padding-top: 71px;
  margin-top: -71px;
}
.section h5 {
  padding-top: 71px;
  margin-top: -71px;
}
.section h6 {
  padding-top: 71px;
  margin-top: -71px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->




<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\/?&!#<>]/g, '').replace(/\s/g, '_').toLowerCase();
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}


.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.9em;
  padding-left: 5px;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>

<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Computing for the Social Sciences</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="faq.html">FAQ</a>
</li>
<li>
  <a href="syllabus.html">Syllabus</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->
<p><strong>This content is from the fall 2016 version of this course. Please go <a href = "https://uc-cfss.github.io">here</a> for the most recent version.</strong></p>

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Web Scraping with Python</h1>
<h4 class="author"><em>Joshua G. Mausolf</em></h4>
<h4 class="date"><em>November 1, 2016</em></h4>

</div>


<div id="prerequisites" class="section level1">
<h1>Prerequisites:</h1>
<p>If you have not already done so, you will need to properly install an Anaconda distribution of Python, following the installation <a href="https://uc-cfss.github.io/setup00.html">instructions from the first week</a>.</p>
<p>I would also recommend installing a friendly text editor for editing scripts such as <a href="https://atom.io">Atom</a>. Once installed, you can start a new script by simply typing in bash <code>atom name_of_your_new_script</code>. You can edit an existing script by using <code>atom name_of_script</code>. <a href="https://www.sublimetext.com">SublimeText</a> also works similar to Atom. Alternatively, you may use a native text editor such as <a href="https://www.linux.com/learn/vim-101-beginners-guide-vim">Vim</a>, but this has a higher learning curve.</p>
<div id="installing-new-python-packages" class="section level3">
<h3>Installing New Python Packages</h3>
<p>One way to install new packages not already included in Anaconda is using <code>conda install &lt;package&gt;</code>. While packages in Anaconda are curated, they are not always the most up to date version. Furthermore, not all packages are available with <code>conda install</code>.</p>
<p>To resolve this issue, use the <a href="https://packaging.python.org/installing/">Python package manager <code>pip</code></a>, which should be installed by default. To begin, <strong>update pip</strong>.</p>
<div id="on-mac-or-linux" class="section level4">
<h4>On Mac or Linux</h4>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">pip</span> install -U pip setuptools</code></pre></div>
</div>
<div id="on-windows" class="section level4">
<h4>On Windows</h4>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">python</span> -m pip install -U pip setuptools</code></pre></div>
<hr />
</div>
</div>
</div>
<div id="using-python-for-webscraping" class="section level1">
<h1>Using Python for Webscraping</h1>
<p>In contrast to <a href="https://github.com/jmausolf/Python_Tutorials/blob/master/Web_Scraping_and_APIs/Querying_APIs_with_Python.Rmd">querying API’s with Python</a>, web-scraping relies on targeting the observed structure of a website itself to download specified content. A good conceptual model for web-scraping is the following example:</p>
<p>Suppose you would like to collect all the speeches and remarks of President Obama during his presidency. You could begin by going to the <a href="https://www.whitehouse.gov/briefing-room/speeches-and-remarks">White House Speeches and Remarks website</a>, finding a speech, copying the text, pasting it in a text file, and saving it. Repeat this process by navigating to the URL for each speech, copy the speech, and save it. Obviously, this would be an onerous experience to do manually. Web-scraping offers a programmatic solution to automate this process.</p>
<p>We will return to a simplified example of scraping presidential speech later in the tutorial. Before we get deeper into this, let’s review the key ideas in web-scraping.</p>
<div id="essential-processes-of-webscraping" class="section level2">
<h2>Essential Processes of Webscraping</h2>
<div id="there-are-two-essential-concepts-of-webscraping" class="section level3">
<h3><em>There are two essential concepts of webscraping</em></h3>
<div id="finding-urls-to-download" class="section level4">
<h4>(1) Finding URLs to Download</h4>
<p>Finding URLs to download is often one of the most challenging parts of web-scraping and is highly dependent on the website layout, URL construction, and formatting. Your basic goal here is to generate a list or CSV of URLs to download. <em>How do I know what the URLs should be?</em></p>
<p>Some sites have very clean URLs:</p>
<pre><code>http://www.example.com/content/file_01_01_2016.txt
http://www.example.com/content/file_01_02_2016.txt
...
http://www.example.com/content/file_12_31_2016.txt</code></pre>
<p>In such a case, the URLs themselves follow a formula. Generating the list of URLs is a simple matter of using string manipulation to create URLs for all possible datetimes that exist in the range you desire.</p>
<p>This is rarely the case. Often URLs will have no programmable format. You must instead collect them. Here the strategy is to begin at the base_URL for your desired site content. From here, there will be one or more links (which lead to one or more link combinations) leading to the final URL. The task is to write a series of loops that recursively go through each possible path to get to the final set of URLs. This is site dependent.</p>
<p>Some sites have pager functions: <strong>Page 1 of X</strong>. Others have JavaScript that dynamically render site content when the user scrolls to the end of the page. Pager functions or other file paths can be solved using BeautifulSoup and URLlib. Dynamic pages are best resolved using a package like Selenium.</p>
<p>These topics are beyond the current scope. Today, we will be emphasizing the most basic of web-scraping tasks, downloading content for a specific URL.</p>
</div>
<div id="downloading-urls" class="section level4">
<h4>(2) Downloading URLs</h4>
<p>Once you have a URL, downloading it can be achieved in various ways, and depends on the format. If your file exists as a plain text file or pdf, you could simply download it from the command line using <code>curl</code> or <a href="https://pypi.python.org/pypi/wget"><code>wget</code></a>.</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="co">#Getting the Congressional Record</span>
<span class="kw">wget</span> https://www.gpo.gov/fdsys/pkg/CREC-2011-09-21/pdf/CREC-2011-09-21.pdf</code></pre></div>
<p>Alternatively, for standard websites, you will often want to use an HTLM parser such as BeautifulSoup.</p>
<p>Note that you could use wget on most websites. For standard websites, however, wget will download the raw HTML (the main web development structure). This is not very readable and much longer than the desired content. Below, I demonstrate a simple implementation of BeautifulSoup to get select speech content.</p>
<hr />
</div>
</div>
</div>
</div>
<div id="an-example-of-elementary-webscraping-in-python" class="section level1">
<h1>An Example of Elementary Webscraping in Python</h1>
<p>Before turning to this example, please note the following web-scraping libraries in Python:</p>
<div id="essential-tools-for-webscraping" class="section level3">
<h3><em>Essential Tools for Webscraping</em></h3>
<div id="key-webscraping-tools" class="section level4">
<h4><em>Key Webscraping Tools</em></h4>
<ul>
<li><h4 id="beautiful-soup"><a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/">Beautiful Soup</a></h4></li>
<li><h4 id="urllib"><a href="https://docs.python.org/3/library/urllib.html">URLlib</a></h4></li>
</ul>
</div>
<div id="advanced-webscraping-tools" class="section level4">
<h4><em>Advanced Webscraping Tools</em></h4>
<ul>
<li><h4 id="selenium-for-advanced-web-scraping"><a href="http://docs.seleniumhq.org">Selenium</a> (For Advanced Web-scraping)</h4></li>
</ul>
</div>
<div id="analysis-tools" class="section level4">
<h4><em>Analysis Tools</em></h4>
<ul>
<li><h4 id="nltk-for-text-analysis"><a href="http://www.nltk.org">NLTK</a> for text analysis</h4></li>
</ul>
<hr />
</div>
</div>
</div>
<div id="downloading-urls-in-python" class="section level1">
<h1>Downloading URL’s in Python</h1>
<p>The <a href="https://github.com/jmausolf/Python_Tutorials">code for this example is available on Github</a>. Please clone the following:</p>
<div class="sourceCode"><pre class="sourceCode bash"><code class="sourceCode bash"><span class="kw">git</span> clone https://github.com/jmausolf/Python_Tutorials</code></pre></div>
<p>To launch Jupyter, go to your Shell and type:</p>
<p><code>jupyter notebook</code></p>
<p>This will launch your web-browser and Jupyter from the location you run the above command. It is recommended you do this immediately after the above <code>git clone</code> to open Jupyter in the correct location. You will have the option to open or navigate to the tutorial notebook, or to start a new one.</p>
<p>Open the folder <code>Webscraping_and_APIs_in_Python</code> and open the notebook <code>Elementary_Web_Scraping.ipynb</code>.</p>
<p>If you cannot launch the notebook, you can <a href="webdata_scrape_py_b.html">view the HTML version here</a>.</p>
<hr />
</div>

<p>This work is licensed under the  <a href="http://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0 Creative Commons License</a>.</p>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
